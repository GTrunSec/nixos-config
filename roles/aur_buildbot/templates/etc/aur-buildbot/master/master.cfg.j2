# -*- python -*-
# ex: set filetype=python:


import re
import os
import os.path
import sys
import collections
import importlib
import itertools

from twisted.logger import Logger
from twisted.internet import defer
import requests
import yaml

from buildbot.plugins import *
import buildbot.process.remotecommand

# Hack to make basedir available in all other modules
basedir = os.path.expanduser(basedir)
import builtins
builtins.basedir = basedir

import packages as pkg
importlib.reload(pkg)

log = Logger('aur_buildbot')

####### CONFIGURATION VARIABLES

config_dir = '/etc/{{ aur_buildbot_name }}/master'
chroot_dir = os.path.join(basedir, 'chroot')

repo_name = 'aur-buildbot'
repo_dir = '/srv/http/aur-buildbot'

config_file = os.path.join(config_dir, 'config.yml')

poll_interval = 3600

with open(config_file, 'r') as stream:
    config = yaml.load(stream)

packages = config['packages']
architectures = config['architectures']

all_packages = pkg.find_dependencies(packages)

# This is the dictionary that the buildmaster pays attention to. We also use
# a shorter alias to save typing.
c = BuildmasterConfig = {}

####### WORKERS

# The 'workers' list defines the set of recognized workers. Each element is
# a Worker object, specifying a unique worker name and password.  The same
# worker name and password must be configured on the worker.
c['workers'] = [
{% for worker in groups['aur_buildbot_worker'] %}
    worker.Worker('{{ worker }}', '{{ hostvars[worker].aur_buildbot_worker_password }}'),
{% endfor %}
]

# 'protocols' contains information about protocols which master will use for
# communicating with workers. You must define at least 'port' option that workers
# could connect to your master with this protocol.
# 'port' must match the value configured into the workers (with their
# --master option)
c['protocols'] = {'pb': {'port': {{ aur_buildbot_port }}}}


####### CHANGESOURCES

# The 'change_source' setting tells the buildmaster how it should find out
# about source code changes.

c['change_source'] = []

# Poll the AUR for changes to each package

try:
    os.mkdir(os.path.join(basedir, 'gitpoller'), mode=0o755)
except FileExistsError:
    pass

for package, info in all_packages.items():
    arch_string = ','.join(info['architectures'])

    c['change_source'].append(changes.GitPoller(pkg.aur_url(package),
        workdir='gitpoller/{}'.format(package), branch='master',
        project=package, category=arch_string, pollinterval=poll_interval,
        pollAtLaunch=True))
    
    # Poll the source repository for VSC packages
    source_number = 0
    if package.endswith('-git'):
        for source in info['sources']:
            if source['vcs'] == 'git' or source['url'].startswith('git://'):
                log.info("Polling git source repository '{url}' for '{pkg}'",
                    url=source['url'], pkg=package)
                c['change_source'].append(changes.GitPoller(source['url'],
                    workdir='gitpoller/{}-{}'.format(package, source_number),
                    project=package, category=arch_string, 
                    pollinterval=poll_interval, pollAtLaunch=True))
                source_number += 1

####### SCHEDULERS

# Configure the Schedulers, which decide how to react to incoming changes.

c['schedulers'] = []

for arch in tuple(architectures) + ('any',):
    c['schedulers'].append(schedulers.SingleBranchScheduler(
        name=arch,
        change_filter=util.ChangeFilter(category_re='.*{}.*'.format(arch)),
        treeStableTimer=None,
        builderNames=[arch]
    ))

    c['schedulers'].append(schedulers.ForceScheduler(
        name="manual_build_{}".format(arch),
        buttonName="Build package",
        label="Manually build package",
        builderNames=[arch],
        reason=util.FixedParameter(name="reason", default="Manually built package"),
        username=util.FixedParameter(name="username", default=""),

        codebases=[
            util.CodebaseParameter(
                "",
                name="Package",
                branch=util.FixedParameter(name="branch", default="master"),

                # will generate nothing in the form, but revision, repository,
                # and project are needed by buildbot scheduling system so we
                # need to pass a value ("")
                revision=util.FixedParameter(name="revision", default=""),
                # will generate a combo box
                repository=util.FixedParameter(name="repository", default=""),
                project=util.ChoiceStringParameter(
                    name="project",
                    choices=[package for package, package_info in all_packages.items() if arch in package_info['architectures']]
                )
            )
        ]
    ))

####### BUILDERS

# The 'builders' list defines the Builders, which tell Buildbot how to perform a build:
# what steps, and which workers can execute them.  Note that any particular build will
# only take place on one worker.

c['builders'] = []

chroot_update_lock = util.WorkerLock('chroot_update_lock')
repo_add_lock = util.MasterLock('repo_add_lock')

class PropertyInitializer(steps.BuildStep):
    def __init__(self, **kwargs):
        super(PropertyInitializer, self).__init__(
            name='Initialize build properties',
            **kwargs
        )

    @defer.inlineCallbacks
    def run(self):
        log = yield self.addLog('output')
    
        # Set extra_dependencies property
        extra_dependencies = tuple(all_packages[self.getProperty('project')].get('extra_dependencies', tuple()))
        
        yield log.addStdout('Extra dependencies: {}'.format(extra_dependencies))
        
        self.setProperty('extra_dependencies', extra_dependencies)
        
        return defer.returnValue(util.SUCCESS)

class FindPackageFiles(steps.BuildStep):

    def __init__(self, arch, workdir=None, **kwargs):
        super(FindPackageFiles, self).__init__(
            name='Find built package files',
            workdir=workdir,
            **kwargs
        )
        self.arch = arch

    @defer.inlineCallbacks
    def run(self):
        # make sure the worker knows about glob
        workerver = (self.workerVersion('glob'))
        if not all(workerver):
            raise WorkerTooOldError('need glob')

        cmd = buildbot.process.remotecommand.RemoteCommand('glob', {'path': os.path.join(self.workdir, '*.pkg.tar.xz')})
        yield self.runCommand(cmd)
        
        log = yield self.addLog('output')
        
        if cmd.didFail():
            return defer.returnValue(cmd.results())

        files = cmd.updates["files"][-1]
        if len(files) == 0:
            yield log.addStderr('No package files found')
            return defer.returnValue(util.FAILURE)

        yield log.addStdout('Found package files: {}'.format(files))
        self.build.addStepsAfterCurrentStep([
            UploadRepoAdd(self.arch, files)
        ])

        return defer.returnValue(util.SUCCESS)


class UploadRepoAdd(steps.MultipleFileUpload):
    def __init__(self, arch, package_files):
        super(UploadRepoAdd, self).__init__(
            name='Upload package files',
            workersrcs=package_files, 
            masterdest="/srv/http/aur-buildbot/{}".format(arch),
            mode=0o644
        )
        self.arch = arch
        self.new_steps = []
    
    def uploadDone(self, result, source, masterdest):
        source = os.path.basename(source)
        # If this is an any package, link to it in all the arch directories
        if self.arch == 'any':
            for real_arch in architectures.keys():
                self.new_steps.append(steps.MasterShellCommand(
                    name='Link \'any\' package to architecture repos',
                    command=['/usr/bin/ln', '-sf', os.path.join(repo_dir, 'any', source), os.path.join(repo_dir, real_arch, source)]
                ))

    def allUploadsDone(self, result, sources, masterdest):
        if self.arch == 'any':
            repo_arches = architectures.keys()
        else:
            repo_arches = [self.arch]
        for repo_arch in repo_arches:
            self.new_steps.append(steps.MasterShellCommand(
                name='Add package to {} repo'.format(repo_arch),
                command=[
                    '/usr/bin/repo-add', '-R', 
                    os.path.join(repo_dir, repo_arch, '{}.db.tar.gz'.format(repo_name))
                ] + [os.path.join(masterdest, os.path.basename(s)) for s in sources],
                locks=[repo_add_lock.access('exclusive')]
            ))
    
        self.build.addStepsAfterCurrentStep(self.new_steps)

common_steps = [
    PropertyInitializer(),
    steps.ShellCommand(
        name='Update chroot',
        command=['/usr/bin/sudo', 'update-chroot', os.path.join(chroot_dir, 'root'), 'pacman', '-Syu'],
        locks=[chroot_update_lock.access('exclusive')],
        haltOnFailure=True,
        flunkOnFailure=True
    ),
    steps.Git(
        name='Download package repo',
        repourl=util.Interpolate('https://aur.archlinux.org/%(prop:project)s.git'),
        branch='master',
        mode='full',
        method='fresh'
    ),
    steps.ShellCommand(
        name='Build package',
        command=['/usr/bin/sudo', 'build-chroot', util.Property('buildername'), util.Property('extra_dependencies', default=tuple())],
        haltOnFailure=True,
        flunkOnFailure=True
    )
]

any_steps = [FindPackageFiles(arch)]
any_factory = util.BuildFactory(common_steps + any_steps)
c['builders'].append(util.BuilderConfig(
    name="any",
    workernames=['HP-Z420', 'Dell-Optiplex-780'],
    factory=any_factory
))

for arch, workers in architectures.items():
    arch_steps = [FindPackageFiles(arch)]
    arch_factory = util.BuildFactory(common_steps + arch_steps)
    c['builders'].append(util.BuilderConfig(
        name=arch,
        workernames=workers,
        factory=arch_factory
    ))


####### BUILDBOT SERVICES

# 'services' is a list of BuildbotService items like reporter targets. The
# status of each build will be pushed to these targets. buildbot/reporters/*.py
# has a variety to choose from, like IRC bots.

c['services'] = []

####### PROJECT IDENTITY

# the 'title' string will appear at the top of this buildbot installation's
# home pages (linked to the 'titleURL').

c['title'] = "AUR Buildbot"
c['titleURL'] = "https://aur.archlinux.org"

# the 'buildbotURL' string should point to the location where the buildbot's
# internal web server is visible. This typically uses the port number set in
# the 'www' entry below, but with an externally-visible host name which the
# buildbot cannot figure out without some help.

c['buildbotURL'] = "https://ben.nsupdate.info/hp-z420/aur-buildbot/"

# minimalistic config to activate new web UI
c['www'] = dict(port={{ buildbot_web_interface_port }}, plugins=dict(waterfall_view={}, console_view={}))

c['buildbotNetUsageData'] = 'basic'

####### DB URL

c['db'] = {
    # This specifies what database buildbot uses to store its state.  You can leave
    # this at its default for all but the largest installations.
    'db_url' : "sqlite:///state.sqlite",
}
